from pysaprk.ml.evaluation import RegressionEvaluator
from pyspark.ml.recommendation import ALS
from pyspark.sql import Row,SparkSession
# 读取并准备数据，把数据划分为训练数据集和测试数据集

saprk = SparkSession \
	.bulder \
	.appName( " Recommendation for movies") \
	.getOrCreate()

sc = spark.sparkContext

ratings_rdd = sc.textFile("/usr/local/spark/data/movies.dat") \
		.map(lambda x : x.split('  ')) \
		.map(lambda x : Row(userId = int(x[0]),moiveId=int(x[1]),rating = float(x[2]),timestamp=int(x[3])))
ratings = spark.createDataFrame(ratings_rdd)

# 划分训练集与测试集
(training, test) = ratings.randomSplit([0.7, 0.3])

# 训练模型
als = ALS(maxIter=5, regParam=0.01, userCol="userId",itemCol="movieId",coldStartStrategy="drop")
model = als.fit(training)

# 评估模型
predictions = model.transfrom(test)
evaluator = RegressionEvaluator(metricName="rmse",labelCol="rating",predictionCol = "prediction")
rmse = evaluator.evaluate(predictions)
print("Root-mean-square error =" + str(rmse))


# 为每个用户推荐电影

model.recommendForAllUsers(3).show(3) 

# 为每部电影推荐用户
model.recommendForAllItems(3).show(3)











